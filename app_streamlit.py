import streamlit as st
import requests
import json
from PIL import Image
import io
import fitz  # PyMuPDF
import tempfile
import os
import time

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="OCR System",
    page_icon="ğŸ”",
    layout="centered",
    initial_sidebar_state="expanded"
)

# Ù†Ù…Ø§Ø°Ø¬ OCR Ù…Ø¹ endpoints Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
OCR_MODELS = {
    "Microsoft TrOCR Printed": {
        "model_id": "microsoft/trocr-base-printed",
        "description": "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø·Ø¨ÙˆØ¹Ø©"
    },
    "Microsoft TrOCR Handwritten": {
        "model_id": "microsoft/trocr-base-handwritten", 
        "description": "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø®Ø· Ø§Ù„ÙŠØ¯"
    },
    "Donut OCR": {
        "model_id": "naver-clova-ix/donut-base-finetuned-cord-v2",
        "description": "Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ù†Ø¸Ù…Ø©"
    },
    "PaddleOCR En": {
        "model_id": "paddlepaddle/paddleocr-en",
        "description": "Ù†Ù…ÙˆØ°Ø¬ PaddleOCR Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"
    }
}

# Ù‚Ø§Ø¹Ø¯Ø© URL Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
HF_BASE_URL = "https://router.huggingface.co/hf-inference/"
HF_STATUS_URL = "https://router.huggingface.co/hf-inference/status/"

def init_session_state():
    """ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©"""
    if 'hf_token' not in st.session_state:
        st.session_state.hf_token = ""
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "Microsoft TrOCR Printed"
    if 'api_status' not in st.session_state:
        st.session_state.api_status = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
    if 'model_ready' not in st.session_state:
        st.session_state.model_ready = False
    if 'last_check' not in st.session_state:
        st.session_state.last_check = None

def get_api_url():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ù†ÙˆØ§Ù† API Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
    model_info = OCR_MODELS.get(st.session_state.selected_model, OCR_MODELS["Microsoft TrOCR Printed"])
    model_id = model_info["model_id"]
    return f"{HF_BASE_URL}models/{model_id}"

def get_status_url():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ù†ÙˆØ§Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    model_info = OCR_MODELS.get(st.session_state.selected_model, OCR_MODELS["Microsoft TrOCR Printed"])
    model_id = model_info["model_id"]
    return f"{HF_STATUS_URL}{model_id}"

def check_model_status():
    """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… endpoint Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
    if not st.session_state.hf_token:
        return {"error": "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Hugging Face Token Ø£ÙˆÙ„Ø§Ù‹"}
    
    headers = {"Authorization": f"Bearer {st.session_state.hf_token}"}
    
    try:
        # ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… API Ø§Ù„Ø¬Ø¯ÙŠØ¯
        status_url = get_status_url()
        response = requests.get(status_url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            status_data = response.json()
            loaded = status_data.get('loaded', False)
            state = status_data.get('state', 'Unknown')
            
            if loaded:
                return {
                    "status": "success", 
                    "message": "âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…",
                    "ready": True,
                    "state": state
                }
            else:
                return {
                    "status": "loading",
                    "message": "ğŸ”„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬",
                    "ready": False,
                    "state": state
                }
                
        elif response.status_code == 404:
            return {
                "status": "error",
                "message": "âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯",
                "ready": False
            }
        else:
            return {
                "status": "error",
                "message": f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚: {response.status_code}",
                "ready": False
            }
            
    except requests.exceptions.Timeout:
        return {
            "status": "error",
            "message": "â° Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„",
            "ready": False
        }
    except Exception as e:
        return {
            "status": "error", 
            "message": f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}",
            "ready": False
        }

def force_load_model():
    """Ø¥Ø¬Ø¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… endpoint Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
    if not st.session_state.hf_token:
        return {"error": "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Hugging Face Token Ø£ÙˆÙ„Ø§Ù‹"}
    
    api_url = get_api_url()
    headers = {"Authorization": f"Bearer {st.session_state.hf_token}"}
    
    try:
        # Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        test_input = {"inputs": "test image data"}
        response = requests.post(api_url, headers=headers, json=test_input, timeout=60)
        
        if response.status_code == 200:
            return {
                "status": "success",
                "message": "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­"
            }
        elif response.status_code in [503, 422]:
            return {
                "status": "loading", 
                "message": "ğŸ”„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 20-30 Ø«Ø§Ù†ÙŠØ©"
            }
        else:
            return {
                "status": "error",
                "message": f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {response.status_code}"
            }
            
    except Exception as e:
        return {
            "status": "error",
            "message": f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}"
        }

def query_ocr_api(image_bytes):
    """Ø¯Ø§Ù„Ø© Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ OCR API Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… endpoint Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
    if not st.session_state.hf_token:
        return {"error": "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Hugging Face Token Ø£ÙˆÙ„Ø§Ù‹"}
    
    headers = {"Authorization": f"Bearer {st.session_state.hf_token}"}
    api_url = get_api_url()
    
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… multipart/form-data Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø©
        files = {'data': image_bytes}
        response = requests.post(api_url, headers=headers, files=files, timeout=60)
        
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 503:
            return {"error": "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø²Ø± 'ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬' Ø£ÙˆÙ„Ø§Ù‹"}
        elif response.status_code == 401:
            return {"error": "Token ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"}
        elif response.status_code == 404:
            return {"error": "Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯"}
        elif response.status_code == 422:
            return {"error": "ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… Ø£Ùˆ Ù‡Ù†Ø§Ùƒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"}
        elif response.status_code == 429:
            return {"error": "ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ø§Ù‹."}
        else:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ API: {response.status_code} - {response.text}"}
            
    except requests.exceptions.Timeout:
        return {"error": "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"}
    except Exception as e:
        return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}"}

def pdf_to_images(pdf_file):
    """ØªØ­ÙˆÙŠÙ„ PDF Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(pdf_file.getvalue())
            tmp_path = tmp_file.name
        
        doc = fitz.open(tmp_path)
        images = []
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_data = pix.tobytes("ppm")
            img = Image.open(io.BytesIO(img_data))
            images.append(img)
        
        doc.close()
        os.unlink(tmp_path)
        return images
        
    except Exception as e:
        return {"error": f"Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ PDF: {str(e)}"}

def preprocess_image(image):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„ØµÙˆØ±Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© OCR"""
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ù„ÙˆÙ†Ø©
    if image.mode != 'L':
        image = image.convert('L')
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ø¬Ù… Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ¯Ø©
    width, height = image.size
    if width > 1200 or height > 1200:
        ratio = min(1200/width, 1200/height)
        new_size = (int(width * ratio), int(height * ratio))
        image = image.resize(new_size, Image.Resampling.LANCZOS)
    
    return image

# ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
init_session_state()

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
with st.sidebar:
    st.title("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API")
    st.markdown("---")
    
    # Ø¥Ø¯Ø®Ø§Ù„ Hugging Face Token
    st.subheader("ğŸ”‘ Hugging Face Token")
    token = st.text_input(
        "Ø£Ø¯Ø®Ù„ Hugging Face Token",
        value=st.session_state.hf_token,
        key="hf_token_input",
        type="password",
        help="Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Token Ù…Ù†: https://huggingface.co/settings/tokens",
        label_visibility="collapsed"
    )
    
    if token != st.session_state.hf_token:
        st.session_state.hf_token = token
        st.session_state.api_status = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
        st.session_state.model_ready = False
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    st.subheader("ğŸ¤– Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    selected_model = st.selectbox(
        "Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ OCR",
        options=list(OCR_MODELS.keys()),
        index=list(OCR_MODELS.keys()).index(st.session_state.selected_model),
        help="Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù†ÙˆØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"
    )
    
    if selected_model != st.session_state.selected_model:
        st.session_state.selected_model = selected_model
        st.session_state.api_status = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
        st.session_state.model_ready = False
    
    # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    if st.session_state.selected_model in OCR_MODELS:
        model_info = OCR_MODELS[st.session_state.selected_model]
        st.caption(f"ğŸ“ {model_info['description']}")
        st.caption(f"ğŸ”— {model_info['model_id']}")
    
    st.markdown("---")
    
    # Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    st.subheader("ğŸ” Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“¡ ÙØ­Øµ Ø§Ù„Ø­Ø§Ù„Ø©", use_container_width=True):
            if st.session_state.hf_token:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
                    status_result = check_model_status()
                
                st.session_state.api_status = status_result["status"]
                st.session_state.model_ready = status_result.get("ready", False)
                st.session_state.last_check = time.time()
                
                if status_result["status"] == "success":
                    st.success(status_result["message"])
                elif status_result["status"] == "loading":
                    st.warning(status_result["message"])
                else:
                    st.error(status_result["message"])
            else:
                st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Token Ø£ÙˆÙ„Ø§Ù‹")
    
    with col2:
        if st.button("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", use_container_width=True):
            if st.session_state.hf_token:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
                    load_result = force_load_model()
                
                if load_result["status"] == "success":
                    st.success(load_result["message"])
                    st.session_state.model_ready = True
                elif load_result["status"] == "loading":
                    st.warning(load_result["message"])
                    st.info("â³ Ø§Ù†ØªØ¸Ø± 30 Ø«Ø§Ù†ÙŠØ© Ø«Ù… Ø§ÙØ­Øµ Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")
                else:
                    st.error(load_result["message"])
            else:
                st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Token Ø£ÙˆÙ„Ø§Ù‹")
    
    # Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    if st.session_state.api_status != "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ":
        status_colors = {
            "success": "ğŸŸ¢",
            "loading": "ğŸŸ¡", 
            "error": "ğŸ”´"
        }
        status_color = status_colors.get(st.session_state.api_status, "âšª")
        st.metric("Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", f"{status_color} {st.session_state.api_status}")
    
    st.markdown("---")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
    st.info("""
    **âœ¨ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯:**
    - Ø§Ø³ØªØ®Ø¯Ø§Ù… Inference Providers API
    - endpoints Ù…Ø­Ø¯Ø«Ø©
    - Ø¯Ø¹Ù… Ø£ÙØ¶Ù„ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
    """)

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title("ğŸ” Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± ÙˆPDF")
st.write("Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ Hugging Face Ù…Ø¹ Ù†Ø¸Ø§Ù… Inference Providers Ø§Ù„Ø¬Ø¯ÙŠØ¯")

# Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
col1, col2, col3 = st.columns(3)
with col1:
    st.info(f"**Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:** {st.session_state.selected_model}")
with col2:
    status_display = {
        "success": "ğŸŸ¢ Ø¬Ø§Ù‡Ø²",
        "loading": "ğŸŸ¡ Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„", 
        "error": "ğŸ”´ Ø®Ø·Ø£",
        "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ": "âšª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
    }
    current_status = status_display.get(st.session_state.api_status, "âšª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
    st.info(f"**Ø§Ù„Ø­Ø§Ù„Ø©:** {current_status}")
with col3:
    if st.session_state.hf_token:
        st.success("ğŸ”‘ Token Ù…ØªÙˆÙØ±")
    else:
        st.error("ğŸ”‘ Token Ù…Ø·Ù„ÙˆØ¨")

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«
st.success("""
**ğŸ”„ ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¥Ù„Ù‰ Ù†Ø¸Ø§Ù… Hugging Face Ø§Ù„Ø¬Ø¯ÙŠØ¯**
- Ø§Ø³ØªØ®Ø¯Ø§Ù… `router.huggingface.co/hf-inference/` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† `api-inference.huggingface.co`
- Ø¯Ø¹Ù… Inference Providers API
- Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø£ÙØ¶Ù„ Ù„Ù„Ø®Ø¯Ù…Ø©
""")

# ØªØ­Ø°ÙŠØ±Ø§Øª
if not st.session_state.hf_token:
    st.error("""
    **âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Hugging Face Token ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ**
    
    - Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ [Hugging Face Settings](https://huggingface.co/settings/tokens)
    - Ø£Ù†Ø´Ø¦ Token Ø¬Ø¯ÙŠØ¯ (Role: Write)
    - Ø£Ø¯Ø®Ù„Ù‡ ÙÙŠ Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ù…Ø®ØµØµ
    """)

elif not st.session_state.model_ready:
    st.warning("""
    **âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…**
    
    - Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± **"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"** ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    - Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ØªØ¸Ù‡Ø± Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ£ÙƒÙŠØ¯
    - Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© 20-30 Ø«Ø§Ù†ÙŠØ© Ù„Ø£ÙˆÙ„ Ù…Ø±Ø©
    """)

# Ù‚Ø³Ù… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
st.subheader("ğŸ“ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù")
uploaded_file = st.file_uploader(
    "Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø£Ùˆ Ù…Ù„Ù PDF", 
    type=["jpg", "jpeg", "png", "bmp", "pdf"],
    label_visibility="collapsed",
    disabled=not st.session_state.model_ready
)

if uploaded_file is not None and st.session_state.hf_token and st.session_state.model_ready:
    if uploaded_file.type == "application/pdf":
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF
        st.info("ğŸ“„ ØªÙ… Ø±ÙØ¹ Ù…Ù„Ù PDF - Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±...")
        
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ PDF Ø¥Ù„Ù‰ ØµÙˆØ±..."):
            pdf_images = pdf_to_images(uploaded_file)
        
        if isinstance(pdf_images, dict) and "error" in pdf_images:
            st.error(f"âŒ {pdf_images['error']}")
        else:
            st.success(f"âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ PDF Ø¥Ù„Ù‰ {len(pdf_images)} ØµÙØ­Ø©")
            
            all_extracted_text = []
            
            for i, img in enumerate(pdf_images):
                st.subheader(f"Ø§Ù„ØµÙØ­Ø© {i+1}")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.image(img, use_container_width=True, caption=f"Ø§Ù„ØµÙØ­Ø© {i+1}")
                
                with col2:
                    if st.button(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {i+1}", key=f"btn_{i}"):
                        with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙØ­Ø© {i+1}..."):
                            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„ØµÙˆØ±Ø©
                            processed_img = preprocess_image(img)
                            
                            img_bytes = io.BytesIO()
                            processed_img.save(img_bytes, format='PNG')
                            img_bytes = img_bytes.getvalue()
                            
                            result = query_ocr_api(img_bytes)
                        
                        if "error" in result:
                            st.error(f"âŒ {result['error']}")
                        else:
                            st.success("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!")
                            
                            if isinstance(result, list) and len(result) > 0:
                                extracted_text = result[0].get('generated_text', '')
                                if extracted_text:
                                    st.text_area(
                                        f"Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {i+1}",
                                        extracted_text,
                                        height=150,
                                        key=f"text_{i}"
                                    )
                                    all_extracted_text.append(f"--- Ø§Ù„ØµÙØ­Ø© {i+1} ---\n{extracted_text}\n")
                            elif isinstance(result, dict) and 'text' in result:
                                extracted_text = result['text']
                                st.text_area(
                                    f"Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {i+1}",
                                    extracted_text,
                                    height=150,
                                    key=f"text_{i}"
                                )
                                all_extracted_text.append(f"--- Ø§Ù„ØµÙØ­Ø© {i+1} ---\n{extracted_text}\n")
            
            if all_extracted_text:
                st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬")
                full_text = "\n".join(all_extracted_text)
                st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„", full_text, height=300)
                
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ ÙƒÙ…Ù„Ù",
                    data=full_text,
                    file_name="Ø§Ù„Ù†Øµ_Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬.txt",
                    mime="text/plain",
                    use_container_width=True
                )
    
    else:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©")
            image = Image.open(uploaded_file)
            st.image(image, use_container_width=True)
        
        with col2:
            st.subheader("Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            if st.button("ğŸ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ", type="primary", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ..."):
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„ØµÙˆØ±Ø©
                    processed_image = preprocess_image(image)
                    
                    img_bytes = io.BytesIO()
                    processed_image.save(img_bytes, format='PNG')
                    img_bytes = img_bytes.getvalue()
                    
                    result = query_ocr_api(img_bytes)
                
                if "error" in result:
                    st.error(f"âŒ {result['error']}")
                else:
                    st.success("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!")
                    
                    extracted_text = ""
                    if isinstance(result, list) and len(result) > 0:
                        extracted_text = result[0].get('generated_text', '')
                    elif isinstance(result, dict) and 'text' in result:
                        extracted_text = result['text']
                    
                    if extracted_text:
                        st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬", extracted_text, height=200)
                        
                        st.download_button(
                            label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ",
                            data=extracted_text,
                            file_name="Ø§Ù„Ù†Øµ_Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬.txt",
                            mime="text/plain",
                            use_container_width=True
                        )

# Ù‚Ø³Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯"):
    st.markdown("""
    ### ğŸš€ Hugging Face Inference Providers API Ø§Ù„Ø¬Ø¯ÙŠØ¯
    
    **Ù…Ø§ Ø§Ù„Ø¬Ø¯ÙŠØ¯:**
    - âœ… Ù†Ø¸Ø§Ù… serverless Ù…Ø­Ø³Ù†
    - âœ… ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    - âœ… API Ù…ÙˆØ­Ø¯ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    - âœ… Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ ÙˆÙ…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø£Ø¹Ù„Ù‰
    
    **Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª:**
    - ğŸ”„ `api-inference.huggingface.co` â†’ `router.huggingface.co/hf-inference/`
    - ğŸ”„ Ø¯Ø¹Ù… Ø£ÙØ¶Ù„ Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    - ğŸ”„ Ø¥Ø¯Ø§Ø±Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬
    
    **Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
    - âš¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø£Ø³Ø±Ø¹
    - ğŸ”„ ØªØ­Ø¯ÙŠØ«Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
    - ğŸ“ˆ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙˆØ³Ø¹ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„
    
    Ù„Ù„Ù…Ø²ÙŠØ¯: [Inference Providers Documentation](https://huggingface.co/docs/inference-providers)
    """)

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.caption("Powered by Hugging Face Inference Providers API | ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯")